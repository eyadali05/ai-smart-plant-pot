{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28baf85c-28a5-4cff-a26b-387725cbf84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found data folder: C:\\Users\\razer\\Documents\\workspace\\AI F.R.I.E.N.D.S\\data_processed\n",
      "Classes detected: 47\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "# Get current notebook directory\n",
    "root = Path().resolve()\n",
    "\n",
    "# Go up one level (since your notebook is inside \"notebooks\")\n",
    "project_root = root.parent\n",
    "processed_root = project_root / \"data_processed\"\n",
    "models_dir = project_root / \"models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Discover classes (sorted for stable label order)\n",
    "if not processed_root.exists():\n",
    "    raise FileNotFoundError(f\"❌ data_processed not found at: {processed_root}\")\n",
    "\n",
    "classes = sorted([p.name for p in processed_root.iterdir() if p.is_dir()])\n",
    "num_classes = len(classes)\n",
    "print(\"✅ Found data folder:\", processed_root)\n",
    "print(\"Classes detected:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4e42ab-2ed6-4875-95b3-6f62c1327843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: 10332 2198 2260\n"
     ]
    }
   ],
   "source": [
    "def clean_path(p: Path) -> str:\n",
    "    # Safe, OS-agnostic paths for tf.data\n",
    "    return str(p).replace(\"\\\\\", \"/\")\n",
    "\n",
    "def get_paths_and_labels(class_names, split):\n",
    "    paths, labels = [], []\n",
    "    for idx, cls in enumerate(class_names):\n",
    "        class_dir = processed_root / cls / split\n",
    "        if not class_dir.exists(): \n",
    "            continue\n",
    "        for img_path in class_dir.glob(\"*\"):\n",
    "            # Skip folders and hidden files (like .ipynb_checkpoints)\n",
    "            if img_path.is_dir() or img_path.name.startswith(\".\"):\n",
    "                continue\n",
    "            paths.append(clean_path(img_path))\n",
    "            labels.append(idx)\n",
    "    return paths, labels\n",
    "\n",
    "train_paths, train_labels = get_paths_and_labels(classes, \"train\")\n",
    "val_paths,   val_labels   = get_paths_and_labels(classes, \"val\")\n",
    "test_paths,  test_labels  = get_paths_and_labels(classes, \"test\")\n",
    "\n",
    "print(\"Counts:\", len(train_paths), len(val_paths), len(test_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9baff3-cbf2-4747-830c-ed9488caf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: We will NOT divide by 255. We'll keep uint8 [0,255] to feed preprocess_input later.\n",
    "\n",
    "def augment_numpy(image_np, rng=None):\n",
    "    \"\"\"Sane-strength Pi-like augmentation: light crop/zoom, brightness/contrast,\n",
    "    mild JPEG artifacts, gentle blur, very light vignette. Returns uint8 image.\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    img = Image.fromarray(image_np)  # HxW x3 uint8\n",
    "\n",
    "    # Random crop/zoom (keep 85–100% area)\n",
    "    if rng.random() < 0.8:\n",
    "        w, h = img.size\n",
    "        scale = rng.uniform(0.85, 1.0)\n",
    "        nw, nh = int(w*scale), int(h*scale)\n",
    "        if nw < w and nh < h:\n",
    "            x0 = rng.integers(0, w - nw + 1)\n",
    "            y0 = rng.integers(0, h - nh + 1)\n",
    "            img = img.crop((x0, y0, x0+nw, y0+nh))\n",
    "        img = img.resize((IMG_SIZE, IMG_SIZE), Image.BICUBIC)\n",
    "    else:\n",
    "        img = img.resize((IMG_SIZE, IMG_SIZE), Image.BICUBIC)\n",
    "\n",
    "    # Brightness/contrast (subtle)\n",
    "    if rng.random() < 0.7:\n",
    "        img = ImageEnhance.Brightness(img).enhance(rng.uniform(0.8, 1.2))\n",
    "    if rng.random() < 0.7:\n",
    "        img = ImageEnhance.Contrast(img).enhance(rng.uniform(0.85, 1.15))\n",
    "\n",
    "    # JPEG compression artifacts (simulate camera)\n",
    "    if rng.random() < 0.5:\n",
    "        from io import BytesIO\n",
    "        buf = BytesIO()\n",
    "        img.save(buf, format=\"JPEG\", quality=int(rng.integers(60, 90)))\n",
    "        buf.seek(0)\n",
    "        img = Image.open(buf).convert(\"RGB\")\n",
    "\n",
    "    # Gentle blur\n",
    "    if rng.random() < 0.3:\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=float(rng.uniform(0.0, 1.0))))\n",
    "\n",
    "    # Very light vignette (radial darkening)\n",
    "    if rng.random() < 0.3:\n",
    "        arr = np.asarray(img).astype(np.float32)\n",
    "        yy, xx = np.mgrid[0:IMG_SIZE, 0:IMG_SIZE]\n",
    "        cx, cy = IMG_SIZE/2, IMG_SIZE/2\n",
    "        r = np.sqrt((xx-cx)**2 + (yy-cy)**2) / (np.sqrt(2)*IMG_SIZE/2)\n",
    "        mask = 1.0 - 0.15*(r**1.5)  # small fade\n",
    "        arr = np.clip(arr * mask[..., None], 0, 255).astype(np.uint8)\n",
    "        img = Image.fromarray(arr)\n",
    "\n",
    "    return np.array(img)  # uint8 [0..255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f9762d-5047-42ce-b40d-0eb62089cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_load(path, target_size=IMG_SIZE):\n",
    "    # Load, RGB, resize; return uint8 [0..255]\n",
    "    img = Image.open(path).convert(\"RGB\").resize((target_size, target_size))\n",
    "    return np.array(img, dtype=np.uint8)\n",
    "\n",
    "def tf_safe_load_and_label(path, label):\n",
    "    # Wrap PIL loader for tf.data\n",
    "    def _load(p):\n",
    "        p = p.numpy().decode()\n",
    "        img = safe_load(p, IMG_SIZE)\n",
    "        return img\n",
    "    img = tf.py_function(_load, [path], Tout=tf.uint8)\n",
    "    img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "    return img, label\n",
    "\n",
    "def tf_augment(image, label):\n",
    "    # Wrap our numpy augmenter → tf op (still uint8 out)\n",
    "    def _aug(x):\n",
    "        x = x.numpy()\n",
    "        return augment_numpy(x)\n",
    "    aug_img = tf.py_function(_aug, [image], Tout=tf.uint8)\n",
    "    aug_img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "    return aug_img, label\n",
    "\n",
    "def make_dataset(paths, labels, training=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(4000, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(tf_safe_load_and_label, num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(tf_augment, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(train_paths, train_labels, training=True)\n",
    "val_ds   = make_dataset(val_paths,   val_labels,   training=False)\n",
    "test_ds  = make_dataset(test_paths,  test_labels,  training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108ee548-0762-4fff-b91c-8ca2dad0d2a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m base \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mMobileNetV3Small(\n\u001b[0;32m      2\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE, \u001b[38;5;241m3\u001b[39m),\n\u001b[0;32m      3\u001b[0m     include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m base\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# freeze first\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# convert to float32 [0..255] first (uint8→float32); DO NOT /255.0\u001b[39;00m\n\u001b[0;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(inputs, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "base = tf.keras.applications.MobileNetV3Small(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "base.trainable = False  # freeze first\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), dtype=tf.uint8)\n",
    "# convert to float32 [0..255] first (uint8→float32); DO NOT /255.0\n",
    "x = tf.cast(inputs, tf.float32)\n",
    "# Keras preprocessing expects [0..255]; maps to [-1,1] internally for MobilenetV3\n",
    "x = tf.keras.applications.mobilenet_v3.preprocess_input(x)\n",
    "x = base(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a90cf0-5b02-497a-a093-23c3fa5b211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, _ in train_ds.take(1):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(img[0].numpy())\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918d9ec-3559-491a-bf93-3a1d362da17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_HEAD = 8\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(models_dir / \"head_best.keras\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=3, restore_best_weights=True\n",
    "    ),\n",
    "]\n",
    "history_head = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_HEAD,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02003f-f527-4cbc-9283-4c5ff215390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze tail\n",
    "for layer in base.layers[:-40]:\n",
    "    layer.trainable = False\n",
    "for layer in base.layers[-40:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "EPOCHS_FT = 10\n",
    "callbacks_ft = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(models_dir / \"finetune_best.keras\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=2, verbose=1\n",
    "    ),\n",
    "]\n",
    "history_ft = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_FT,\n",
    "    callbacks=callbacks_ft,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
