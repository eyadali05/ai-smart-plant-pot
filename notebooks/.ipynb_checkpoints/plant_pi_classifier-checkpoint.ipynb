{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plant Classifier \u2014 Pi\u2011Camera Robust (TF 2.12)\n",
        "\n",
        "Ready\u2011to\u2011run training notebook:\n",
        "- Clean **tf.data** pipeline with safe loading (skips bad files)\n",
        "- **Pi\u2011camera realistic augmentation** (noise, JPEG artifacts, light blur, vignette, color tint, crop/zoom)\n",
        "- **MobileNetV3Small** transfer learning (freeze \u2192 fine\u2011tune)\n",
        "- **TFLite INT8** export for Raspberry Pi\n",
        "- Callback to save **side\u2011by\u2011side augment samples** per epoch\n",
        "\n",
        "> Assumes your processed dataset is at `../data_processed/<class>/{train,val,test}/*.jpg` relative to this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1 \u2014 Imports & paths (TF 2.12)\n",
        "import os, random, math, json, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "import cv2\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# repo structure (adjust if different)\n",
        "ROOT = Path.cwd().parent  # if notebook is in notebooks/, parent is repo root\n",
        "processed_root = ROOT / \"data_processed\"\n",
        "models_dir = ROOT / \"models\"\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "augment_samples_dir = models_dir / \"augment_samples\"\n",
        "augment_samples_dir.mkdir(exist_ok=True)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32  # reduce to 16 if OOM\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# load class names from folder names\n",
        "classes = sorted([p.name for p in processed_root.iterdir() if p.is_dir()])\n",
        "num_classes = len(classes)\n",
        "print(\"Classes:\", num_classes)\n",
        "assert num_classes > 1, \"No classes found in data_processed. Expected subfolders per class.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2 \u2014 Helpers\n",
        "def clean_path(p):\n",
        "    return str(p).replace(\"\\\\\",\"/\")\n",
        "\n",
        "def get_paths_and_labels(class_names, split):\n",
        "    paths, labels = [], []\n",
        "    for idx, cls in enumerate(class_names):\n",
        "        p = processed_root / cls / split\n",
        "        if not p.exists():\n",
        "            continue\n",
        "        for f in p.iterdir():\n",
        "            if f.is_file():\n",
        "                paths.append(clean_path(f))\n",
        "                labels.append(idx)\n",
        "    return paths, labels\n",
        "\n",
        "def show_batch_paths(paths, n=4):\n",
        "    # PIL-only preview to avoid TF decode issues\n",
        "    import random\n",
        "    picked = random.sample(paths, min(n, len(paths)))\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i, path in enumerate(picked):\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\").resize((224,224))\n",
        "            title = Path(path).parent.parent.name  # class folder\n",
        "            plt.subplot(1, len(picked), i+1)\n",
        "            plt.imshow(img); plt.title(title, fontsize=9); plt.axis(\"off\")\n",
        "        except Exception as e:\n",
        "            print(\"Preview skip:\", path, e)\n",
        "    plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) One-time dataset cleaner\n",
        "You already cleaned previously; skip this unless you add new images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "# Cell 3 \u2014 (Optional) Cleaner \u2014 SKIP if already cleaned\n",
        "RUN_CLEANER = False  # set True and run once if needed\n",
        "if RUN_CLEANER:\n",
        "    bad_files = []\n",
        "    converted_files = 0\n",
        "    checked_files = 0\n",
        "    def is_image_ok(path):\n",
        "        try:\n",
        "            img = Image.open(path); img.verify(); return True\n",
        "        except Exception:\n",
        "            return False\n",
        "    def convert_to_jpeg(path):\n",
        "        nonlocal_converted = 0\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "            new_path = Path(path).with_suffix(\".jpg\")\n",
        "            img.save(new_path, \"JPEG\", quality=95)\n",
        "            os.remove(path)\n",
        "            return True\n",
        "        except Exception:\n",
        "            return False\n",
        "    for cls in classes:\n",
        "        for split in [\"train\",\"val\",\"test\"]:\n",
        "            folder = processed_root / cls / split\n",
        "            if not folder.exists():\n",
        "                continue\n",
        "            for f in folder.iterdir():\n",
        "                if not f.is_file():\n",
        "                    continue\n",
        "                checked_files += 1\n",
        "                if f.suffix.lower() not in [\".jpg\",\".jpeg\",\".png\",\".bmp\"]:\n",
        "                    if not convert_to_jpeg(f):\n",
        "                        bad_files.append(str(f))\n",
        "                    continue\n",
        "                if not is_image_ok(f):\n",
        "                    try:\n",
        "                        img = Image.open(f).convert(\"RGB\")\n",
        "                        img.save(f, \"JPEG\", quality=92)\n",
        "                    except Exception:\n",
        "                        bad_files.append(str(f))\n",
        "    for bf in bad_files:\n",
        "        try:\n",
        "            os.remove(bf)\n",
        "        except Exception:\n",
        "            pass\n",
        "    print(\"Cleaner done. Bad removed:\", len(bad_files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4 \u2014 Pi-camera realistic augmentation (NumPy + PIL)\n",
        "from io import BytesIO\n",
        "\n",
        "def augment_numpy(image_np, rng=None):\n",
        "    \"\"\"Pi-camera style: crop/zoom, brightness/contrast, green tint,\n",
        "    JPEG artifacts, gaussian noise, slight motion blur, vignette, median filter.\n",
        "    Input: uint8 HxWx3; Output: uint8 HxWx3\n",
        "    \"\"\"\n",
        "    if rng is None:\n",
        "        rng = np.random.default_rng()\n",
        "    img = Image.fromarray(image_np)\n",
        "\n",
        "    # 1) Random crop/zoom\n",
        "    if rng.random() < 0.8:\n",
        "        w, h = img.size\n",
        "        scale = rng.uniform(0.85, 1.0)\n",
        "        new_w, new_h = int(w*scale), int(h*scale)\n",
        "        left = int(rng.integers(0, max(1, w-new_w)))\n",
        "        top  = int(rng.integers(0, max(1, h-new_h)))\n",
        "        img = img.crop((left, top, left+new_w, top+new_h))\n",
        "        img = img.resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)\n",
        "    else:\n",
        "        img = img.resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)\n",
        "\n",
        "    # 2) Brightness & contrast\n",
        "    if rng.random() < 0.6:\n",
        "        img = ImageEnhance.Brightness(img).enhance(float(rng.uniform(0.7, 1.25)))\n",
        "    if rng.random() < 0.6:\n",
        "        img = ImageEnhance.Contrast(img).enhance(float(rng.uniform(0.7, 1.25)))\n",
        "\n",
        "    # 3) Slight green tint\n",
        "    if rng.random() < 0.5:\n",
        "        arr = np.array(img).astype(np.float32)\n",
        "        arr[:, :, 1] = np.clip(arr[:, :, 1] * float(rng.uniform(0.98, 1.06)), 0, 255)\n",
        "        img = Image.fromarray(arr.astype(np.uint8))\n",
        "\n",
        "    # 4) JPEG artifacts\n",
        "    if rng.random() < 0.5:\n",
        "        q = int(rng.uniform(35, 85))\n",
        "        buf = BytesIO(); img.save(buf, format=\"JPEG\", quality=q); buf.seek(0)\n",
        "        img = Image.open(buf).convert(\"RGB\")\n",
        "\n",
        "    # 5) Gaussian noise\n",
        "    if rng.random() < 0.5:\n",
        "        arr = np.array(img).astype(np.float32)\n",
        "        noise = rng.normal(0, float(rng.uniform(5, 20)), arr.shape)\n",
        "        arr = np.clip(arr + noise, 0, 255)\n",
        "        img = Image.fromarray(arr.astype(np.uint8))\n",
        "\n",
        "    # 6) Slight motion blur\n",
        "    if rng.random() < 0.3:\n",
        "        k = int(rng.integers(3, 8))\n",
        "        kernel = np.zeros((k, k), dtype=np.float32)\n",
        "        if rng.random() < 0.5:\n",
        "            kernel[k//2, :] = 1.0 / k\n",
        "        else:\n",
        "            kernel[:, k//2] = 1.0 / k\n",
        "        arr = np.array(img)\n",
        "        arr = cv2.filter2D(arr, -1, kernel)\n",
        "        img = Image.fromarray(arr)\n",
        "\n",
        "    # 7) Vignette / shadows\n",
        "    if rng.random() < 0.35:\n",
        "        arr = np.array(img).astype(np.float32)\n",
        "        h, w, _ = arr.shape\n",
        "        y, x = np.ogrid[:h, :w]\n",
        "        dist = np.sqrt((x - w/2)**2 + (y - h/2)**2)\n",
        "        mask = 1 - 0.6 * (dist / np.sqrt(w*w + h*h))\n",
        "        mask = np.clip(mask, 0.4, 1).astype(np.float32)\n",
        "        arr *= mask[..., None]\n",
        "        img = Image.fromarray(arr.astype(np.uint8))\n",
        "\n",
        "    # 8) Median filter\n",
        "    if rng.random() < 0.3:\n",
        "        img = img.filter(ImageFilter.MedianFilter(size=3))\n",
        "\n",
        "    return np.array(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5 \u2014 TF wrappers: safe loader + augmentation\n",
        "def safe_load_and_label(path, label):\n",
        "    \"\"\"Read JPEG/PNG safely; if fails, mark with label -1.\"\"\"\n",
        "    def _load(p):\n",
        "        p = p.numpy().decode()\n",
        "        try:\n",
        "            img = Image.open(p).convert(\"RGB\")\n",
        "            img = img.resize((IMG_SIZE, IMG_SIZE))\n",
        "            arr = np.array(img).astype(np.float32) / 255.0\n",
        "            return arr\n",
        "        except Exception:\n",
        "            # return a dummy; label will be filtered out\n",
        "            return np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.float32)\n",
        "    img = tf.py_function(_load, [path], Tout=tf.float32)\n",
        "    img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    return img, label\n",
        "\n",
        "def tf_augment(image, label):\n",
        "    def _aug(img):\n",
        "        img = img.numpy()\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        aug = augment_numpy(img)\n",
        "        return (aug.astype(np.float32) / 255.0)\n",
        "    aug_img = tf.py_function(_aug, [image], Tout=tf.float32)\n",
        "    aug_img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    return aug_img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6 \u2014 Build datasets\n",
        "train_paths, train_labels = get_paths_and_labels(classes, \"train\")\n",
        "val_paths,   val_labels   = get_paths_and_labels(classes, \"val\")\n",
        "test_paths,  test_labels  = get_paths_and_labels(classes, \"test\")\n",
        "print(len(train_paths), len(val_paths), len(test_paths))\n",
        "\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "    .shuffle(4000, reshuffle_each_iteration=True)\n",
        "    .map(safe_load_and_label, num_parallel_calls=AUTOTUNE)\n",
        "    .filter(lambda img, lbl: tf.not_equal(lbl, -1))\n",
        "    .map(tf_augment, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "    .map(safe_load_and_label, num_parallel_calls=AUTOTUNE)\n",
        "    .filter(lambda img, lbl: tf.not_equal(lbl, -1))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
        "    .map(safe_load_and_label, num_parallel_calls=AUTOTUNE)\n",
        "    .filter(lambda img, lbl: tf.not_equal(lbl, -1))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Quick visual PIL-only\n",
        "show_batch_paths(val_paths, n=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7 \u2014 Model: MobileNetV3Small (freeze \u2192 fine-tune)\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "base = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False, weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False  # freeze backbone initially\n",
        "\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = tf.keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
        "x = base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8 \u2014 Callback: save side-by-side augment each epoch\n",
        "class SaveAugmentSamples(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, sample_path, out_dir):\n",
        "        super().__init__()\n",
        "        self.sample_path = sample_path\n",
        "        self.out_dir = Path(out_dir); self.out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.original = Image.open(sample_path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        orig = self.original\n",
        "        aug  = Image.fromarray(augment_numpy(np.array(orig)))\n",
        "        orig.save(self.out_dir / f\"epoch_{epoch+1:02d}_original.jpg\")\n",
        "        aug.save(self.out_dir / f\"epoch_{epoch+1:02d}_augmented.jpg\")\n",
        "        side = Image.new(\"RGB\", (IMG_SIZE*2, IMG_SIZE))\n",
        "        side.paste(orig, (0,0)); side.paste(aug, (IMG_SIZE,0))\n",
        "        side.save(self.out_dir / f\"epoch_{epoch+1:02d}_side_by_side.jpg\")\n",
        "        print(f\"Saved augment samples for epoch {epoch+1}\")\n",
        "\n",
        "sample_image_path = val_paths[0] if len(val_paths)>0 else train_paths[0]\n",
        "save_aug_cb = SaveAugmentSamples(sample_image_path, augment_samples_dir / \"epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9 \u2014 Train (frozen backbone)\n",
        "EPOCHS_HEAD = 10\n",
        "history_head = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_HEAD,\n",
        "    callbacks=[save_aug_cb],\n",
        ")\n",
        "\n",
        "best_model_dir = models_dir / \"ckpts_v3\"\n",
        "best_model_dir.mkdir(exist_ok=True)\n",
        "model.save(best_model_dir / \"head_trained.keras\", include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10 \u2014 Fine-tune last layers (unfreeze tail)\n",
        "for layer in base.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "for layer in base.layers[-40:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "EPOCHS_FT = 5\n",
        "history_ft = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS_FT,\n",
        "    callbacks=[save_aug_cb],\n",
        ")\n",
        "\n",
        "model.save(best_model_dir / \"finetuned.keras\", include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11 \u2014 Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 12 \u2014 Save labels and SavedModel\n",
        "final_saved = models_dir / \"plant_classifier_savedmodel\"\n",
        "model.save(final_saved, include_optimizer=False)\n",
        "labels_path = models_dir / \"labels.txt\"\n",
        "with open(labels_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for cls in classes:\n",
        "        f.write(cls + \"\\n\")\n",
        "print(\"Saved:\", final_saved)\n",
        "print(\"Labels:\", labels_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 13 \u2014 TFLite INT8 conversion (with representative dataset)\n",
        "def representative_dataset_gen():\n",
        "    # sample up to 200 training images as calibration set\n",
        "    import random\n",
        "    sample = random.sample(train_paths, min(200, len(train_paths)))\n",
        "    for p in sample:\n",
        "        try:\n",
        "            img = Image.open(p).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
        "            arr = np.array(img).astype(np.float32)/255.0\n",
        "            yield [np.expand_dims(arr, 0)]\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(str(final_saved))\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter._experimental_disable_batchmatmul_unfolding = True  # stability tweak\n",
        "\n",
        "tflite_bytes = converter.convert()\n",
        "(models_dir / \"plant_model_int8.tflite\").write_bytes(tflite_bytes)\n",
        "print(\"Saved:\", models_dir / \"plant_model_int8.tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 14 \u2014 Quick TFLite correctness + speed check (CPU)\n",
        "interpreter = tf.lite.Interpreter(model_path=str(models_dir / \"plant_model_int8.tflite\"))\n",
        "interpreter.allocate_tensors()\n",
        "inp = interpreter.get_input_details()[0]\n",
        "out = interpreter.get_output_details()[0]\n",
        "\n",
        "# pick one validation image\n",
        "img = Image.open(val_paths[0]).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
        "x = np.array(img).astype(np.uint8)  # uint8 for INT8 model\n",
        "x = np.expand_dims(x, 0)\n",
        "\n",
        "# warmup\n",
        "for _ in range(5):\n",
        "    interpreter.set_tensor(inp['index'], x)\n",
        "    interpreter.invoke()\n",
        "\n",
        "# timing\n",
        "import time\n",
        "N=50; t0=time.time()\n",
        "for _ in range(N):\n",
        "    interpreter.set_tensor(inp['index'], x)\n",
        "    interpreter.invoke()\n",
        "t1=time.time()\n",
        "avg_ms = (t1-t0)/N*1000\n",
        "pred = interpreter.get_tensor(out['index'])[0]\n",
        "idx = int(np.argmax(pred))\n",
        "print(f\"Avg inference: {avg_ms:.2f} ms | Pred: {classes[idx]}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}